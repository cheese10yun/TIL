> [엘라스틱 스택 개발 부터 운영까지](http://www.yes24.com/Product/Goods/103030516) 정리

# 01 엘라스틱 스택 이란

## 엘라스틱 스택의 구성요소

엘라스틱 스택은 일반적으로 빅데이터 파이프라인을 구성하기 위한 데이터 수집, 가공, 저장 분석, 시각화에 필요한 모든 소프트웨어를 갖추고 있다. 비츠와 로그스태시는 데이터를 수집하고 가공 하는 역할을 맡으며, 엘라스틱서치는 저장하고 분석하는 역할을 담당하고, 키바나는 엘라스틱 서치에 저장된 데이터를 시작화하고 모니터링하는 역할을 수행한다.

### 엘라스틱서치: 분산 검색 엔진
엘라스틱서치 검색 엔진은 내부적으로 각 도큐먼트를 인덱싱 하고 빠르게 검색하는데 사용한다. 엘라스틱서치는 모든 레코드를 JSON 도큐먼트 형태로 입력하고 관리하며, 일반적인 데이터베이스와 마찬가지로, 쿼리한 결과에 대해 일치하는 원번 도큐먼트를 반환한다.
엘라스틱서치를 일종의 NoSQL 데이터베이스라고 생각하면 훨씬 더 큰 그림이 보얼것이다.

엘라스틱서치에 대한 기본적인 사용 경험은 몽고디비 같은 도큐먼트 기반의 NoSQL과 유사하다. 하지만 다른 NoSQL 제품을 압독하는 검색 기능과 엘라스틱서치의 가장 큰 특징이자 활용 먹적이라 볼 수 있다. 또한 검색 엔진ㅇ,로서 엘라스틱서치의 중요한 특징 중 하나는 스코어링, 즉 연관도에 따른 정렬이다. 단순히 필드 값을 기준으로 한 정렬은 어떤 데이터 베이스라도 제공하지만, 엘라스틱서치는 검색어에 대한 유사도 스코어를 기반으로 한 정렬을 제공한다. 이는 특히 복잡한 문자열 콘텐츠에서 검색을 수행할 때 큰 효과를 보인다.

엘라스틱서치 클러스터는 분산 시스템으로 분산 시스템으로서 엘라스틱서치는 복수의 루씬 인스턴스를 병렬로 배치하고 분산 처리해 검색 속도를 무한히 확장할 수 있게 했다. 또 노드 간 복제 기능을 통해 일부 노드가 다운되더라도 정상적인 서비스를 지속할 수 있게 했다. 무엇보다도 REST API를 이용하도록 만들어 프로그래밍 언어와 무관하게 사용자가 쉽게 접근할 수 있도록 활용성을 높였다.

물론 단점도 있다. 저장공간이 크게 압축되지 않고 시스템 리소스를 많이 사용한다. 엘라스틱서치는 DSL 쿼리를 채용하는데 JSON 쿼리가 사실상 어렵기 때문에 반정규화를 기본으로 모델링 해야한다. 또한 인덱스가 불변의 자료구조이기 떄문에 도뮤컨트를 수정하가나 삭제할 경우에 비용이 저렴하지 않다. 하지만 이러한 단점들은 검색 기능을 끌어올리 기 위해 어느정도 트레이드오프가 이뤄진 것으로, 엘라스틱서치가 필요한 수준의 대량 데이터를 처리할 떄는 일반적으로 용인이되는 제약들이다.

### 키바나: 시각화와 엘라스틱서치 관리도구
엘라스틱서치에 대한 대부분의 관리 기능, API를 실행할 수 있는 콘솔, 솔루 션 페이지들, 그리고 스택의 각 구성요소들을 위한 모니터링 페이지 등이 모두 키마나에 포함되 있다. 하지만 엘라스틱서치 기반의 시각화 도구로서 키바나의 가장 중요한 기능은 시각화와 대시보드라고 할 수 있다. 키바나는 일반적으로 많이 사용되는 라인 파츠, 파이 차트 등과 테이블 지도 등의 다양한 시각화 요소들을 클릭 몇 번으로 쉽게 구성할 수 있게 해준다.


### 로그스태시: 에빈트 수집과 정제를 위한 도구
대량의 데이터를 검색하기 위해 가장 먼저 선행돼야 할 작업은 데이터를 적재하는 것이다. 데이터 수집과 가공 기능을 제공하는 로스스태시를 사용하면 로그, 메트릭, 웹 애플리케이션 등 다양한 소스로부터 로그를 수집할 수 있다.

로그스태시는 별도의 코딩 없이 간단한 설정만으로 로그를 가공할 수 있다. 확장 가능한 200개의 이사으이 프럴그인 덕분에 설정이 대부분 플러그인 사용 방법인데 그 사용법이 크게 어렵지 않다.

로그스태시가 익숙하지 않다는 이유로 로그스태시가 아닌 커스텀 애플리케이션을 작성해 소스 데이터를 수집하려는 경우도 있다. 로ㅓ그스태시는 진면목은 단순 소스 데이터 정제가 아니다. 엘라스틱서치의 인덱싱 성능을 최적화하기 위해 배치 처리와 병렬 처리가 가능하며, 영속적인 큐를 사용해 연재 처리 중인 이벤트의 최소 1회 전송을 보장해줄 뿐만 아니라. 유동적인 처리 방식으로 인해 수집 중인 데이터양이 급증하는 부하 상황에서도 안정성을 보장해 준다. 이를 커스텀 애플리케이션으로 구현할 경우 신겅 써야 할 부분이 많고 문제 발생 시 디버깅이나 튜닝이 쉽지 않다는 점에서 따라오기 어려운 로그스태시의 장점이라 할 수 있다.


### 비츠: 엣지단에서 동작하는 경량 수집 도구
로그스테시의 기능은 충분히 가엵하다. 하지만 이벤트 정보를 수집하기 위해 실제 서비스가 동작하는 호스트에 수집기를 설치해야 하는 경우가 많은데 로그스태시는 다양한 필터와 설정을 지원하는 만큼 무겁기 때문에 이러한 목적으로 활용도가 떨어질 수 있다. 엘라스틱 스택에는 이를 위해 파일비츠, 메트릭비트 등 비츠라고 부르는 경량 수집기가 포함되어 있다. 각 비트는 로그수집, 시스템 지표 수집 등 특정 목적에 최적화된 에이전트이며, 가볍기로 유명한 고 프로그래밍 언어로 작성되어 있다. 또한 로그스태시 수준의 복잡한 이벤트 가공은 지원하지 않아 가벼우므로, 각 서비스 호스트에 비교적 부담 없이 설치 할 수 있다. 이러한 양쪽의 장점을 활용하기 위해 비츠와 로그스태시를 혼합해 많이 사용한다.


### 기타 솔루션
애플리케이션 성능 모니터링을 위한 APM, 보안 이벤트 분석을 위한 SIEM, 컨테이너 다수의 서비스를 쉽게 모니터링하기 위한 인프라 모니터링 등의 솔루션이 포함되어 있다.

## 엘라스틱 스택의 용도

### 전문 검색

엘라스틱 스택의 가장 기본적인 사용처는 바로 전문 검색 엔진 구현이다. 전문 검색은 단순한 문장부터 뉴스 기사나 논문 등 다양한 글의 전체 내용을 의미한다. 대상 도큐먼트가 많지 않는 다면 일반적인 관계형 데이터베이스의 LIKE 질의 검색으로도 충분히 가능하지만 도큐먼트 수가 조금만 늘어나도 인덱스의 도움 없이 빠른 검색은 불가능에 가깝다.

이러한 전문을 빠르고 정확하게 검색하기 위해 전문 용어를(terms) 단위로 분석해 인덱싱해 두고 이를 기반으로 검색을 수행하는 역인덱싱 기법이 많이 활용된다. 

![](https://raw.githubusercontent.com/cheese10yun/TIL/master/assets/elk-1-1.png)
* Discover 으로 사전에 등록한 인덱스 패턴 데시보드 지원

### 로그 통합 분석
엘라스틱 스택은 여러 장비와 서비스에서 발생하는 로그를 통합하고 검색하는 데 최적화된 솔루션이라 할 수 있다. 시스템과 호스트, 쿠버네티스, 아파치, MySQL 다양한 환경에서 생성되는 로그를 별도의 복잡한 구성 없이도 바로 수집 가능하다. 비츠를 사용하면 적은 리소스로 각 장비의 로그들을 빠르게 쉬집할 수 있고, 로그스태시는 다양한 필터를 통해 일원화된 형태로 가공을 도유며, 엘라스틱서치의 대용량 로그에 대한 빠른 인덱싱 성능과 텍스트 검색 능력은 여러 곳에 흩어진 서비스 로그들을 통합해서 연관 분석을 지원한다.

![](https://raw.githubusercontent.com/cheese10yun/TIL/master/assets/elk-1-2.png)
* Stream 형식으로 로그를 스트리밍 하여 실시간으로 확인 가능


### 보안 이벤트 분석
SIEM 등으로 불리는 솔루션은 조직 내에 속한 다양한 장비들로부터 보안 이벤트를 수집하고 분석 할 수 있게 하려는 목적으로 만들어 졌다. 키바나에서 제공하는 엘라스틱 이벤트 분석 화면에서 비츠에서 수집한 이벤트를 기반으로 엔드포인 활용, 인프라스트럭처, 클라우드, 네트워크 등 다양한 소스에서 수집한 이벤트를 기반으로 엔트포인트 활동, 인증 로그, DNS 트래픽, 네트워크 플로우에서 이상 징후, 불법적인 로그인 시고, 사용자 접근 패턴 등의 문제를 빠르게 찾아낼 뿐만 아니라, SIEM UI에서 분석을 비롯한 고유 탐지 규칙 관리 또한 가능하다.

### 애플리케이션 성능 분석
앨라스틱 스택의 애플리케이션 성능 모니터링 도구인 APM은 프로그래밍 언어별 에이전트를 통해 성능 지표를 수집하고 돕고 분석을 위한 UI를 제공한다. 그 뿐만 아니라 메트릭비트와 패킷비트를 사용하면 시스템을 비롯해 여기 연계된 다양한 서비스들의 성능 정보를 수집할 수 있게 도와준다.

유료서비스 크립션에 포함된 기능인 와처나 머신러닝 등의 기능과 연계하면 장애나 이상 상황을 빠르게 파악하고 원인을 효과적으로 분석할 수 있다.

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/spring-msa/docs/images/apm-1-6.png)
* 위에 설정한 APM 서버 확인

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/spring-msa/docs/images/apm-1-7.png)
* 해당 애플리케이션 트랜잭션 정보를 출력합니다. 보다 자세히 보고 싶으면 해당 트랜잭션을 클릭해서 자세한 내용을 확인할 수 있습니다.

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/spring-msa/docs/images/apm-1-8.png)
* 해당 트랜잭션 내용을 살펴볼 수 있으며, HTTP 요청/응답에 대한 자세한 내용도 확인 가능합니다.

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/spring-msa/docs/images/apm-1-9.png)
* 해당 쿼리 문의 상세한 내용도 확인할 수 있습니다.

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/spring-msa/docs/images/apm-1-11.png)
* 해당 서버의 Error를 보여줍니다.
* 발생한 Error를 클릭하면 해당 오류의 더 많은 정보를 확인할 수 있습니다.

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/spring-msa/docs/images/apm-1-12.png)
* 오류가 발생한 트랜잭션을 클릭하면 트래잭션 탭으로 이동되며, 해당 이슈의 원인을 파악을 도와줍니다.

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/spring-msa/docs/images/apm-1-10.png)
* 현재 시스템 리소스에 대한 내용을 확인할 수 있습니다.


![](https://raw.githubusercontent.com/cheese10yun/TIL/master/assets/elk-1-3.png)

* query 통계
* slow query 분포도 및 정렬
* error query 획인

![](https://raw.githubusercontent.com/cheese10yun/TIL/master/assets/elk-1-4.png)

* CURD 쿼리 Count
* Threads created rate 
* Running threads
* Connections rate

![](https://raw.githubusercontent.com/cheese10yun/TIL/master/assets/elk-1-5.png)

![](https://raw.githubusercontent.com/cheese10yun/TIL/master/assets/elk-1-6.png)


## 빅데이터 플랫폼의 일부로 동작하는 엘라스틱 스택

### 엔터프라이즈 데이터 버스인 카프카와 연동
아파츠 카프카는 분산 데이터 스트리밍 플랫폼이다, 대량의 데이터를 실사간으로 배포하는 데 최적화되어 있어 많은 빅 데이터 플랫폼에서 기본적으로 채택하고 있다.

비츠에서 수집한 각 장비의 이벤트를 카프카로 전소앟고 이를 로그스태시로 다시 읽어 들이거나 카프카에 저장된 다른 시스템의 이벤트를 엘라스틱서치로 읽어 들이는 등의 구성으로 자주 사용된다.

### 하둡 생톄개와 연동
엘라스틱서치는 이미 인덱싱된 결과에 대해 빠른 검색을 제공하고 스파크는 기존에 인덱싱되지 않은 데이터에 대한 빠른 일괄 처리를 제공학 ㅣ때문에 엘라스틱서치를 중간 집계 엔진이나 결과를 저장해 재활용하는 용도 등으로 활용할 수 있다.

### 관계형 데이터베이스와 연동

관계형 데이터베이스에는 주로 레거시 데이터나 신뢰성이 중요한 데이터가 포함되어 있다. 로그스태시는 JDBC 입력 플러그인, 필터 등 관계형 데이터베이스와 연계할 수 있는 다양한 방법을 제공하고 있다. 기존 관계형 데이터베이스에 저장된 데이터를 인덱싱하거나 입력받은 이벤트에 정보를 중비하는 등 여러 용도로 사용된다. JDBC 입력 플러그인을 사용해 관계형 데이터베이스에 저장된 데이터를 엘라스틱서치로 이전할 경우, 엘라스틱 스택의 우수한 성능을 이용해 관계형 데이터베이스로는 처리하기 어려운 집계도 빠르고 정확하게 처리 할 수 있다. 또한 텍스트 데이터의 경우 엘라스틱서치에서는 색인만 수행하고 원문을 저장하지 않게 설정하는 방식을 이용해 저장소 용량을 아끼면서 저장소 용량을 아낄 수 있다. JDBC 필터를 사용하는 경우 관계형 데이터베이스에서 실 데이터를 불러와 매핑하는 용도로 이벤트에 ID 형태로만 기록되는 정보를 활용 할 수있다.


## 유사 제품과 비교

### 엘라스틱서치의 유사 제품군

특징 | 엘라스틱서치 | 몽고디비 | MySQL
--|--------|------|------
분류 | 검색 엔진 | 도뮤컨트 저장소 | 관계형 데이터베이스
최초 릴리즈 | 2010 | 2009 | 1995
스키마 | 자동 생성 | 자유 | 필요
인터페이스 | REST API | 전용 프로토컬 | JDBC/ODBC
분산 저장 | 샤딩 | 샤딩 | 별도 제품으로 지원
트랜잭션 | 미지원 | 부분 지원 | 지원
Join | 미지원 | 최근 도뮤컨트 단위로 지원 시작 | 지원
특징 | 다양한 데이터 유형에 대해 빠른 검색/집계 | 높은 활용성/범용성 | 뛰어난 데이터 무결성


### 로그스태시/비츠의 유사 제퓸군
데이터 플랫폼에 사용되는 유사한 제품으로 트레저 데이터에서 개발한 플루언트디 와 비교할 수 있는데, 플루언트디는 로그스태시와 설정의 형태만 다를 뿐 기능상으로 건의 동일한 역할을 수행 할 수 있다. 다만 엘라스틱 스택에 한정 지어 사영한다면 로그스태시는 엘라스틱서치, 키바나와 연계해 모니터링, 중앙 관리 등의 기능을 제공하는 한편, 플루언트디는 이러한 지원을 받을 수 없기 때문에 되도록 로그스태시와 비츠의 조합이 권장된다.

### 키바나의 유사 제품군

특징 | 키바나 | 그라파나 | 태블로
---|-----|------|----
실행환경 | 웹 서비스 | 웹 서비스 | 설치/웹 서비스 모두 제공
데이터 소스 | 엘라스틱서치 | 엘라스틱서치,그라파이트,몽고디비,프로메테우스 등 | 관계형 데이터베이스, 엑셀 파일, JOSN 파일, 드롭박스등
특징 | 실시간 대시보드 외에도 캔버스 지도, 비츠/로그스태시와 연계되어 제공되는 롯루션 등 엘라스틱 서치와의 기능을 십분 활용한 다양한 시각화 세트 제공 | 라인, 바 차트 등 기본적이지만 인프라 모니터링에 부족함이 없는 시각화 요소들 포함 | 실시간보다는 다양한 시각화 도구를 이용한 분석에 특화되어 있음
기타 기능 지원 | 스택 관리, 모니터링 등 엘라스틱 스택 특화 기능 지원, 알림이나 머신러닝 등 유료 기능 존재 | 알림 기능 지원 | -


# 03 엘라스틱서치 기본

## 엘라스틱서치 요청과 응답

엘라스틱서치는 모든 요청과 응답을 REST API 형태로 제공한다.

## 키바나 콘솔 사용법

![](https://raw.githubusercontent.com/cheese10yun/TIL/master/assets/elk-1.png)

키바나 콘솔을 시용하면 복잡한 앱 개발이나 프로그램 설치 없이 엘라스틱서치와 REST API로 통신 할 수 있다.

## 인덱스와 도큐먼트

일반적으로 엘라스틱을 이용해 시스템을 개발하면 하나의 프로젝트에서 하나의 클러스터를 생성한다. 그리고 클러스터 내부는 데이터 성격에 따라 여러 개의 인덱스를 생성한다.

### 도큐먼트

도큐먼트는 엘라스틱서치에서 데이터가 저장되는 기본 단위로 JSON 형태며, 하나의 도큐먼트는 야러 필드와 값을 갖는다. 엘라스틱서치가 도큐먼트에 데이터를 어떻게 저장하는지 알아보고, 우리가 흔히 아는 관계형 데이터베이스와 엘라스틱서치의 데이터 저장 방식도 비교해 보자.

```
name: mike
age: 25
genger: male
```
일반적인 관계형 데이터베이스는 SQL 문을 이용해 데이터를 저장한다.

```sql
CREATE TABLE meber (
    uuid int not null AUTO_INCREMENT PRIMARY KEY,
    name varchar(50) not null,
    age int not null,
    genger varchar(6) not null
)

INSERT INTO meber (name, age, genger) values ("moke", age, "male");
```

member라는 테이블에 name, age, genger 칼럼을 가진 스키마가 있어야 하고, 하나의 레코드로 데이터를 저장한다. 반면 엘라싁서치는 데이터를 JSON 형태로 저장한다.

```json
{
    "name": "mike",
    "age": 25,
    "genger": "male"
}
```
name, age, genger를 필드라고 하며 "mike", 25, "male"을 값이라고 한다.

MySQL | 엘라스틱서치
------|-------
데이터베이스 | 인덱스
테이블 | 타입


### 인덱스

인덱스는 도뮤컨트를 저장하는 론리적인 단위로, 관계형 데이터베이스의 테이블과 유사한 개념이다. 하나의 인덱스에 다수의 도큐먼트가 포함되는 구조인데, 동일한 인덱스에 있는 도큐먼컨트는 동일한 스키마를 갖는다. 그리고 모든 도뮤컨트는 반드시 하나의 인덱스에 포함돼야 한다.


## 도큐먼트 CRUD

### 인덱스 생성/확인/삭제
도큐먼트 CURD 동작을 하기 위해서는 반드시 인덱스가 있어야 한다.

```
PUT index1

{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "index" : "index1"
}
```
index1 이라는 이름의 인덱스를 생성하는 API다.

```
GET index1

{
  "index1" : {
    "aliases" : { },
    "mappings" : { },
    "settings" : {
      "index" : {
        "creation_date" : "1644759999450",
        "number_of_shards" : "1",
        "number_of_replicas" : "1",
        "uuid" : "vgFoG30CR5mGPeg-i59_jQ",
        "version" : {
          "created" : "7060299"
        },
        "provided_name" : "index1"
      }
    }
  }
}

```
인덱스를 확인 하는 API이다. 

```
DELETE index1

{
  "acknowledged" : true
}
```
인덱스를 삭제하는 API이다. 인덱스를 삭제하면 인덱스에 저장되어 있는 도큐먼트들도 모두 삭제 되나 주의해야 한다.

### 도큐먼트 생성
엘라스틱서치에서 도큐먼트를 인덱스에 포함시키는 것을 인덱싱 이라고 한다.

```
PUT index2/_doc/1
{
  "name":"mike",
  "age": 25,
  "genger": "male"
}

{
  "_index" : "index2",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}
```
index2라는 인덱스를 생성하면서 동시에  index2 인덱스에 도큐먼트를 인덱싱한다. index2는 인덱스 이름, _doc은 엔드포인트 구분을 위한 예약어, 숫자 1은 인덱싱할 도큐먼트의 고유 아이디이다.

```
GET index2

{
  "index2" : {
    "aliases" : { },
    "mappings" : {
      "properties" : {
        "age" : {
          "type" : "long"
        },
        "genger" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "name" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        }
      }
    },
    "settings" : {
      "index" : {
        "creation_date" : "1644760221176",
        "number_of_shards" : "1",
        "number_of_replicas" : "1",
        "uuid" : "5P4QNPFrSZ2nepjUd7KhLg",
        "version" : {
          "created" : "7060299"
        },
        "provided_name" : "index2"
      }
    }
  }
}

```

index2 인덱스는 mappings에 age는 long 타입, genger와 name은 text, 타입으로 필드가 지정되어 있다. 우리가 데이터 타입을 지정하지 않아도 엘라스틱서치는 도큐먼트의 필드와 값을 보고 자동으로 지정하는데, 이런 기능을 다이내믹 매핑이라고 한다.


이번에는 index2 인덱스에 country라는 이름의 새로운 필드가 추가된 도큐먼트를 인덱싱 해보자

```
PUT index2/_doc/2
{
  "name":"jane",
  "country": "fracne"
}
```
2번 도큐먼트에는 country 필드가 추가되었고 기존에 있던 age, gender 필드는 사용하지 않지만 그래도 문제가 없이 인덱싱 된다.

이번에는 잘못된 데이터 타입을 입력한 도큐먼트를 인덱싱 해보자

```
PUT index2/_doc/3
{
  "name":"kim",
  "age": "25",
  "genger": "male"
}
```
관계형 데이터베이스라면 오류가 발생했겠지만 스키마에 유연하게 대응하는 엘라스틱서치는 타입을 변환해 저장한다.

3번 도뮤컨트는 age 필드 값이 인덱싱 과정에서 상제로 숫자 타입으로 변경 ("20" -> 20)되었다.


### 도큐먼트 읽기

도큐먼트를 읽는 방법은 크게 도큐먼트 아이드를 이용해 조회하는 방법과 쿼리 DSL 이라는 엘라스틱서치가 제공하는 쿼리문을 이요해 검색하는 방법이 있다. 우선 도큐먼트 아이디를 사용해 조회하는 방법부터 살펴보자

```
GET index2/_doc/1

{
  "_index" : "index2",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 2,
  "_seq_no" : 2,
  "_primary_term" : 1,
  "found" : true,
  "_source" : {
    "name" : "kim",
    "age" : "25",
    "genger" : "male"
  }
}
```
인덱스명과 도큐먼트 아이디를 이용해 특정 도큐먼트의 데이터를 가져올 수 있다. 실제에서는 단일 조회보다는 search라는 DSL 쿼리를 이용해 도큐먼트를 읽어오는 방법을 많이 사용한다.

### 도큐먼트 수정

```
PUT index2/_doc/1
{
  "name": "park",
  "age": 45,
  "genger": "male"
}

{
  "_index" : "index2",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 3,
  "result" : "updated",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 5,
  "_primary_term" : 1
}

```
기존 1번 도큐먼트의 name, age 필드의 값이 변경되 었다. 응답 결과 result 필드를 통해 도큐먼트라 생성되었고 업데이트되고 삭제 되는 상태를 알 수 있다.

Update API를 이용해 특정 도쿠먼트의 값을 업데이트할 수 있다.

```
POST index2/_update/1
{
  "doc":{
    "name": "lee"
  }
}

{
  "_index" : "index2",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 4,
  "result" : "updated",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 6,
  "_primary_term" : 1
}

```
_update라는 엔드포인트를 추가해 특정 필드 값만 업데이트할 수 있다. 

엘라스틱서치 도큐먼트 수정 작업은 비용이 많이 들기 떄문에 권장하지 않는다. 특히 엘라스틱서치를 로그 수집 용도로 사용한ㄷ가면 개별 도큐먼트를 수정할 일은 거의 없다. 개별 도큐먼트 수정이 많은 작업이라면 엘라스틱서치가 아닌 다른 데이터베이스를 이용하는 것이 좋다.

### 도큐먼트 삭제

index2 인덱스에 아이디 2번 도큐먼트가 삭제된다. 다만 도큐먼트 수정과 마찬가지로 개별 도큐먼트 삭제 또한 비용이 많이 들어가는 작업인 만큼 사용 시에 주의하자.

```
DELETE index2/_doc/2
{
  "_index" : "index2",
  "_type" : "_doc",
  "_id" : "2",
  "_version" : 2,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 7,
  "_primary_term" : 1
}

```

## 응답 메시지
HTTP Status Code        상태        해결 방법
200, 201        정상적으로 수행함       -
4xx     클라이언트 오류     클라언트에서 문세점 수정
404     요청한 리소스가 없음        인덱스나 도큐먼트가 존재하는지 체크
405     요청 메서드를 지원하지 않음         API 사용법 다시 확인
429     요청 과부화     재전송, 노드 추가 같은 조치
5xx     서버 오류       엘라스틱서치 로그 확인 후 조치

## 벌크 데이터
벌크 데이터는 대량의 데이터를 생성, 수정, 삭제를 하는 경우를 말한다. 각 줄 사이에는 쉼표 등 별도의 구분자가 없고 라인 사이 공백을 허용하지 않는다. JSON 문법 처럼 보이지만 복수의 JSON 구조를 줄바꿈 문자열로 구분하는 NDJSON 형태이다.

```
POST _bulk
{"index": {"_index": "index2", "_id": "4"}}
{"name": "park", "age": 30, "genger": "female"}
{"index": {"_index": "index2", "_id": "5"}}
{"name": "jung", "age": 50, "genger": "male"}
```

## 매핑
관계형 데이터베이스는 테이블을 만들 때 반드시 스카마 설계가 필요하다. 여기서 말하는 스키마는 테이블을 구성하는 구성요소 간의 논리적인 관계와 정의를 의미한다. 구조를 명확히 하지 않고는 테이블이 생성되지 않고, 추후에 인덱싱 칼럼이나 조인 칼럼 등에서도 문제가 발생하기 때문이다. 엘라스틱서치에서도 관계형 데이터베이스의 스키마외 비슷한 역할을 하는 것이 있는데 바로 매핑이다. 쉽게 말하면 JSON 형태의 데이터를 루씬이 이해할 수 있도록 바꿔주는 작업이다. 엘라스틱서치가 검색 엔진으로 전문 검색과 대량 데이터를 빠르게 실시간 검색할 수 있는 이유는 매핑이 있기 때문인데 매핑을 엘라스틱서치가 자동으로 하면 다이내믹 매핑, 사영자가 직접 설정하면 명시적 매핑이다. 

엘라스틱서치에서는 문자열을 텍스트와 키워드 타입으로 나눌 수 있는데, 전문 검색을 활용하려면 반드시 두 가지 타입을 이해하고 있어야 한다.

### 다이내믹 매핑
엘라스틱서치의 머ㅗ든 인덱스는 매핑 정보를 갖고 있지만 우ㅠ연한 활용을 위해 인덱스 생성 시 매핑 정의를 강제하지 않는다. 특별히 데이터 타입이나 스키마에 고민하지 않아도 JSON 도큐먼트의 데이터에 맞춰 엘라스틱서치가 자동으로 인덱스 매핑을 해주는 것이다.

##### 다이내믹 매핑 기준
원본 소스 데이터 타입 | 다이내믹 매핑으로 변환된 데이터 타입
-------------|---------------------
null | 필드를 추가하지 않음
boolean | boolean
float | float
integer | long
object | object
string | string 데이터 형태에 따라 date, text/keyword 필드

다이내믹 매핑이 적용된 index2 인덱스의 매핑을 확인해보자. 엘라스틱서치는 인덱스 매핑값을 확인할 수 있는 mappings API를 제공하고 있다.

```
GET index2/_mapping

{
  "index2" : {
    "mappings" : {
      "properties" : {
        "age" : {
          "type" : "long"
        },
        "country" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "genger" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        },
        "name" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        }
      }
    }
  }
}
```

인덱스의 규모가 커진다면 효율이 떨어진다. 일례로 age 필드는 사람 나이인데 200 살을 넘는 데이터는 없기 떄문에 long 타입 보다는 메모리를 조금쓰는 short 타입이 유리할 것이다. 또한 country나 gender 같은 범주형 데이터는 전문 검색보다는 일반적으로 집계나 정렬, 필터링을 위해서 사용되기 때문에 키워드 타입으로 지정되는 것이 좋다.

### 명시적 매핑
인덱스 매핑을 직접 정의하는 것을 명시적 매핑이라고 한다. 인덱스를 생성할 때 mappings 정의를 설정하거나 mapping API를 이용해 매핑을 지정할 수 있다.

```
PUT index3
{
  "mappings":{
    "properties": {
      "age": {"type": "short"},
      "name": {"type": "text"},
      "gender": {"type": "keyword"}
    }
  }
}

{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "index" : "index3"
}
```

```
GET index3/_mapping

{
  "index3" : {
    "mappings" : {
      "properties" : {
        "age" : {
          "type" : "short"
        },
        "gender" : {
          "type" : "keyword"
        },
        "name" : {
          "type" : "text"
        }
      }
    }
  }
}

```
지정된 필드명과 필드 타입으로 인덱스가 매핑되었다. 저장할 데이터를 확실히 알고 있다면 인덱스를 생성할 때 직접 매핑하는 것이 좋다. 인덱스 매핑이 정해지면 새로운 필드를 추가할 수 있으나, 이미 정의돈 필드를 수정하거나 삭제할 수는 없다. 필드 이름을 변경하거나 데이터 타입을 변경하기 위해서는 새로운 인덱스를 만들거나 reindex API를 이영해야 하니 매핑 작업은 신중하게 하는 것이 좋다.


### 매핑 타입

데이터 형태 | 데이터 타입 | 설명
-------|--------|---
텍스트 | text | 전문 검색이 필요한 데이터로 텍스트 분석기가 텍스트를 작은 단위로 분리한다.
텍스트 | keyword | 정렬이나 집계에 사영되는 텍스트 데이터로 분석을 하지 않고 원문을 통쨰로 인덱싱 한다.
날짜 | date | 날짜/시간 데이터
정수 | byte,short,intger,long | * byte: 부호있는 8비트 데이터(-128~127) <br> * short: 부호 있는 16비트 (-32,768~32,767) <br> * integer: 부호 있는 32 비트 데이터<br> * long: 부호 있는 64 비트 데이터<br>
실수 | scaled_float, half_float, dobule, float | * scaled_float: float 데이터에 특정 값을 곱해서 정수형으로 바꾼 데이터, 정확도는 떨어지나 필요에 따라 집계 등에서 효율적으로 사용 가능하다.<br> * half_float: 16비트 부동소수점 실수 데이터<br> * dobule: 32비트 부동소수점 실수 데이터<br> * float: 64 비트 부동소수점 실수 데이터<br>
불린 | boolean | true/false
IP 주소 | ip | ipv4, ipv6 타입 IP 주소
위치 정보 | geo-point, geo-shape | * geo-point: 위도, 경도 값<br> * geo-shape: 하나의 위치 포인트가 아닌 임의의 지형<br>
범위 값 | integer_range, long_range, float_range, double_range, ip_range, date_ragne | 범위를 설정할 수 잇는 데이터, 범위 값을 저장하고 검색할 수 있게한다.
객체형 | object | 계층형 구조를 갖는 형태로 필드 안에 다른 필드들이 들어갈 수 있다. name: {"first": "kim", "last": "tony"}로 타입을 정의하면 name.fist, name.last 형태로 접근할 수 있다.
배열형 | nested | 배열형 객체를 저아한다. 객체를 따로 인덱싱하여 객체가 하나로 합쳐지는 것을 막고, 배열 내부에의 객체에서 쿼리로 접근할 수 있다.
배열형 | join | 부모/자식 관계를 표현할 수 있다.

### 멀티 필드를 활용한 문자열 처리
엘라스틱 서치 5.x 버전부터 문자열 타입이 텍스트와 키워드 두 가지 타입으로 분리되어 있다.

#### 텍스트 타입

#### 키워드 타입

#### 멀티 필드

## 인덱스 템플릿

### 템플릿 엔진

### 템플릿 설정

#### 템플릿 생성

#### 템플릿 적용

#### 템플릿 삭제

### 템플릿 우선순위

